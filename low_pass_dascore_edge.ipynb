{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-frequency DAS Edge Processing Using [DASDASE](https://github.com/DASDAE)\n",
    "\n",
    "This Jupyter Notebook is created for low-frequency processing of a [spool](https://dascore.org/tutorial/concepts.html#:~:text=read%20the%20docs!-,Data%20structures,-DASCore%20has%20two) of distributed acoustic sensing (DAS) data in real-time. It uses [DASCore](https://dascore.org/) package and the ```lf_das.py``` script.\n",
    "\n",
    "\n",
    "<svg width=\"100%\" height=\"1\">\n",
    "  <line x1=\"0\" y1=\"0\" x2=\"100%\" y2=\"0\" style=\"stroke:rgb(0,0,0);stroke-width:2\" />\n",
    "</svg>\n",
    "\n",
    "\n",
    "#### Notes: \n",
    "1. Before using this notebook, make sure you have included the ```lf_das.py``` script in the current directory with this notebook and successfully installed DASCore using ```pip``` or ```conda```:\n",
    "    ```python\n",
    "    pip install dascore\n",
    "    ```\n",
    "    or\n",
    "    ```python\n",
    "    conda install dascore -c conda-forge\n",
    "    ```   \n",
    "2. Please find all supported I/O [here](https://dascore.quarto.pub/dascore/).\n",
    "\n",
    "Current DASCore version: 0.0.13 (tested)\n",
    "\n",
    "Date: 09/07/2023\n",
    "\n",
    "\n",
    "Contact: [Ahmad Tourei](https://github.com/ahmadtourei/)\n",
    "\n",
    "ahmadtourei@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import dascore as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "from datetime import datetime\n",
    "from lf_das import LFProc, get_edge_effect_time, get_patch_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a spool of data to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data path (spool of data) and output folder \n",
    "data_path = '/mnt/h/data'\n",
    "output_data_folder =  '/mnt/h/results'\n",
    "output_figure_folder = '/mnt/h/figures'\n",
    "\n",
    "# get the sorted spool of data form the defined data path (on first run, it will index the patches and subsequently update the index file for future uses)\n",
    "sp = dc.spool(data_path).sort(\"time\").update()\n",
    "\n",
    "# print the contents of first 5 patches\n",
    "content_df = sp.get_contents()\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some metadata and define a sub spool (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sampling rate, channel spacing, and gauge length from the first patch\n",
    "patch_0 = sp[0]\n",
    "gauge_length = patch_0.attrs['gauge_length']\n",
    "print(\"Gauge length = \", gauge_length)\n",
    "channel_spacing = patch_0.attrs['step_distance']\n",
    "print(\"Channel spacing = \", channel_spacing)\n",
    "sampling_interval = patch_0.attrs['step_time']\n",
    "print(\"Sampling interval = \", sampling_interval)\n",
    "sampling_rate = 1/(sampling_interval / np.timedelta64(1, 's'))\n",
    "print(\"Sampling rate = \", sampling_rate)\n",
    "num_sec = len(patch_0.coords[\"time\"])/sampling_rate\n",
    "print(\"Number of seconds in each patch= \", num_sec)\n",
    "\n",
    "# select a sub-spool\n",
    "ch_start = 400\n",
    "ch_end = 1400\n",
    "d_1 = patch_0.coords['distance'][ch_start] # in meter\n",
    "d_2 = patch_0.coords['distance'][ch_end] # in meter\n",
    "# or:\n",
    "# d_1 = -115 # in meter\n",
    "# d_2 = 2000 # in meter\n",
    "sub_sp = sp.select(distance=(d_1, d_2)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get low-pass filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the memory size that you'd like to dedicate to low-frequency processing \n",
    "memory_size = 10000 # in MB\n",
    "patch_length = get_patch_time(memory_size=memory_size, sampling_rate=sampling_rate, num_ch=ch_end-ch_start)\n",
    "print('patch_length = ', patch_length, str(' sec.'))\n",
    "\n",
    "# define the target sampling interval in seconds\n",
    "d_t = 10.0 # so, cutoff_freq = Nyq_new = 1/(2*d_t) = 0.05 hz\n",
    "\n",
    "# define the desired tolerance for getting the edge time (smaller tolerance results a longer eliminated edges in each patch and higher accuracy. 1e-3 is recommended.)\n",
    "tolerance = 1e-3\n",
    "edge_buffer = get_edge_effect_time(sampling_interval=1/sampling_rate, total_T=patch_length, tol=tolerance, freq=1/d_t)\n",
    "print('edge_buffer = ', edge_buffer, str(' sec.'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set real-time processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the desired wait time after each run\n",
    "time_step_for_processing = 125 # in sec.\n",
    "\n",
    "# make sure that the wait time is not smaller than number of seconds of each data file\n",
    "if time_step_for_processing<num_sec:\n",
    "    time_step_for_processing = num_sec\n",
    "\n",
    "# make sure that the wait time is larger than the patch length multiplied by a buffer factor\n",
    "if time_step_for_processing<(2*edge_buffer)*1.5:\n",
    "    time_step_for_processing = (2*edge_buffer)*1.5\n",
    "    if patch_length > time_step_for_processing:\n",
    "        patch_length = time_step_for_processing\n",
    "\n",
    "print(\"time_step_for_processing: \", time_step_for_processing)\n",
    "print(\"patch length: \", patch_length)\n",
    "\n",
    "# set the starting time from which low-freq. processing applys (it can be the time_min for the first patch of the spool)\n",
    "start_processing_time = np.datetime64('2023-03-22T06:00:00') # in UTC, or any other time zone that original data are stored \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do low-frequency processing in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the for loop for real-time processing\n",
    "initial_run = True\n",
    "while True:\n",
    "    # select a updated sub-spool\n",
    "    sp = dc.spool(data_path).update()\n",
    "    sub_sp = sp.select(distance=(d_1, d_2)) \n",
    "    len_updated_sp = len(sub_sp)\n",
    "\n",
    "    if not initial_run and len_last_sp == len_updated_sp:\n",
    "        print(\"No new data was detected. Real-time processing ended successfully.\")\n",
    "        break\n",
    "\n",
    "    # pass the spool to the LFProc class\n",
    "    lfp = LFProc(sub_sp)\n",
    "    lfp.update_processing_parameter(output_sample_interval=d_t, process_patch_size=int(patch_length/d_t), edge_buff_size=int(np.ceil(edge_buffer/d_t)))\n",
    "    # set the output folder - Caution: If you set delete_existing=True, you will remove all contents in the output_data_folder directory. If you set delete_existing=False, you need to have a empty output_data_folder directory to proceed.\n",
    "    lfp.set_output_folder(output_data_folder, delete_existing=False)\n",
    "\n",
    "    if initial_run:\n",
    "        i=1\n",
    "        print(\"run number: \", i)\n",
    "        t_1 = start_processing_time\n",
    "        t_2 = np.datetime64(sub_sp[-1].attrs['time_max'])\n",
    "        # do lowpass processing on (t_1,t_2) time range\n",
    "        lfp.process_time_range(t_1,t_2)\n",
    "        initial_run = False \n",
    "        len_last_sp = len(sub_sp)\n",
    "        time.sleep(time_step_for_processing)\n",
    "    else:\n",
    "        i+=1\n",
    "        print(\"run number: \", i)\n",
    "        t_2 = lfp.get_last_processed_time() \n",
    "        buffer = int((np.ceil(edge_buffer/d_t)-1)*d_t) \n",
    "        t_1 = t_2 - np.timedelta64(buffer, 's') \n",
    "        t_2 = np.datetime64(sub_sp[-1].attrs['time_max'])\n",
    "        # do lowpass processing on (t_1,t_2) time range\n",
    "        lfp.process_time_range(t_1,t_2)\n",
    "        len_last_sp = len(sub_sp)\n",
    "        time.sleep(time_step_for_processing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dascore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
