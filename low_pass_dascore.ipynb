{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-frequency DAS Processing Using [DASDASE](https://github.com/DASDAE)\n",
    "\n",
    "This Jupyter Notebook is created for low-frequency processing of a [spool](https://dascore.org/tutorial/concepts.html#:~:text=read%20the%20docs!-,Data%20structures,-DASCore%20has%20two) of distributed acoustic sensing (DAS) data. It uses [DASCore](https://dascore.org/) package and the ```lf_das.py``` script and it is inspired by Dr. Ge Jin's [low frequency processing](https://github.com/DASDAE/DASLowFreqProcessing). \n",
    "\n",
    "\n",
    "<svg width=\"100%\" height=\"1\">\n",
    "  <line x1=\"0\" y1=\"0\" x2=\"100%\" y2=\"0\" style=\"stroke:rgb(0,0,0);stroke-width:2\" />\n",
    "</svg>\n",
    "\n",
    "\n",
    "#### Notes: \n",
    "1. Before using this notebook, make sure you have included the ```lf_das.py``` script in the current directory with this notebook and successfully installed DASCore using ```pip``` or ```conda```:\n",
    "    ```python\n",
    "    pip install dascore\n",
    "    ```\n",
    "    or\n",
    "    ```python\n",
    "    conda install dascore -c conda-forge\n",
    "    ```   \n",
    "2. Please find all supported I/O [here](https://dascore.quarto.pub/dascore/).\n",
    " \n",
    "\n",
    "Current DASCore version: 0.0.12\n",
    "\n",
    "Date: 08/17/2023\n",
    "\n",
    "\n",
    "Contact: [Ahmad Tourei](https://github.com/ahmadtourei/)\n",
    "\n",
    "ahmadtourei@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import dascore as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from time import time\n",
    "from lf_das import LFProc, get_edge_effect_time, get_patch_time, waterfall_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a spool of data to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>dims</th>\n",
       "      <th>data_category</th>\n",
       "      <th>cable_id</th>\n",
       "      <th>time_min</th>\n",
       "      <th>file_version</th>\n",
       "      <th>tag</th>\n",
       "      <th>file_format</th>\n",
       "      <th>path</th>\n",
       "      <th>data_type</th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>station</th>\n",
       "      <th>time_max</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>time,distance</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-02-19 18:08:55.318832</td>\n",
       "      <td>2.1</td>\n",
       "      <td></td>\n",
       "      <td>PRODML</td>\n",
       "      <td>BM73-22_UTC_20230219_180855.318.h5</td>\n",
       "      <td>strain_rate</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-02-19 18:09:55.317832</td>\n",
       "      <td>0 days 00:00:00.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>time,distance</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-02-19 18:09:55.318833</td>\n",
       "      <td>2.1</td>\n",
       "      <td></td>\n",
       "      <td>PRODML</td>\n",
       "      <td>BM73-22_UTC_20230219_180955.318.h5</td>\n",
       "      <td>strain_rate</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-02-19 18:10:55.317833</td>\n",
       "      <td>0 days 00:00:00.001000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network           dims data_category cable_id                   time_min  \\\n",
       "0          time,distance                        2023-02-19 18:08:55.318832   \n",
       "1          time,distance                        2023-02-19 18:09:55.318833   \n",
       "\n",
       "  file_version tag file_format                                path  \\\n",
       "0          2.1          PRODML  BM73-22_UTC_20230219_180855.318.h5   \n",
       "1          2.1          PRODML  BM73-22_UTC_20230219_180955.318.h5   \n",
       "\n",
       "     data_type instrument_id station                   time_max  \\\n",
       "0  strain_rate                       2023-02-19 18:09:55.317832   \n",
       "1  strain_rate                       2023-02-19 18:10:55.317833   \n",
       "\n",
       "               time_step  \n",
       "0 0 days 00:00:00.001000  \n",
       "1 0 days 00:00:00.001000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define data path and output folder locations and then pass the data directory to the spool\n",
    "data_path = '/mnt/h/data'\n",
    "output_data_folder =  '/mnt/h/results'\n",
    "output_figure_folder = '/mnt/h/figures'\n",
    "\n",
    "# get the spool of data form the defined data path (will index patches for the first time)\n",
    "sp = dc.spool(data_path)\n",
    "\n",
    "# print the contents of first 5 patches\n",
    "content_df = sp.get_contents()\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some metadata and define a sub spool (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadtourei/anaconda3/envs/dascore/lib/python3.11/site-packages/tables/attributeset.py:291: DataTypeWarning: Unsupported type for attribute 'TriggeredMeasurement' in node 'Acquisition'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauge length =  10.0\n",
      "Channel spacing =  2.0419039726257324\n",
      "Sampling interval =  1000000 nanoseconds\n",
      "Sampling rate =  1000.0\n"
     ]
    }
   ],
   "source": [
    "# get sampling rate, channel spacing, and gauge length from the first patch\n",
    "patch_0 = sp[0]\n",
    "gauge_length = patch_0.attrs['gauge_length']\n",
    "print(\"Gauge length = \", gauge_length)\n",
    "channel_spacing = patch_0.attrs['d_distance']\n",
    "print(\"Channel spacing = \", channel_spacing)\n",
    "sampling_interval = patch_0.attrs['d_time']\n",
    "print(\"Sampling interval = \", sampling_interval)\n",
    "sampling_rate = 1/(sampling_interval / np.timedelta64(1, 's'))\n",
    "print(\"Sampling rate = \", sampling_rate)\n",
    "\n",
    "# select a sub-spool if you'd like to\n",
    "t_1 = '2023-08-01 10:00:00'\n",
    "t_2 = '2023-08-02 10:00:00'\n",
    "ch_start = 400\n",
    "ch_end = 1400\n",
    "d_1 = patch_0.coords['distance'][ch_start] # in meter\n",
    "d_2 = patch_0.coords['distance'][ch_end] # in meter\n",
    "# or:\n",
    "# d_1 = -115 # in meter\n",
    "# d_2 = 2000 # in meter\n",
    "sub_sp = sp.select(distance=(d_1, d_2), time=(t_1, t_2)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get low-pass filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_length =  208.33333333333334  sec.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Field elements must be 2- or 3-tuples, got '0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# define the desired tolerance for getting the edge time (smaller tolerance results a longer eliminated edges in each patch and higher accuracy. 1e-3 is recommended.)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tolerance \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m\n\u001b[0;32m---> 11\u001b[0m edge_buffer \u001b[39m=\u001b[39m get_edge_effect_time(sampling_interval\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49msampling_rate, total_T\u001b[39m=\u001b[39;49mpatch_length, tol\u001b[39m=\u001b[39;49mtolerance, freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49md_t)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39medge_buffer = \u001b[39m\u001b[39m'\u001b[39m, edge_buffer, \u001b[39mstr\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m sec.\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[39m# pass the spool to the LFProc class\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/SpoolProcessing_LowFreq/lf_das.py:62\u001b[0m, in \u001b[0;36mget_edge_effect_time\u001b[0;34m(sampling_interval, total_T, fun, tol, **kargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m     60\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39md_time\u001b[39m\u001b[39m\"\u001b[39m: sampling_interval, \u001b[39m\"\u001b[39m\u001b[39md_distance\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}\n\u001b[0;32m---> 62\u001b[0m newdata \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39;49mPatch(data\u001b[39m=\u001b[39;49mdata, coords\u001b[39m=\u001b[39;49mcoords, dims\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdistance\u001b[39;49m\u001b[39m\"\u001b[39;49m], attrs\u001b[39m=\u001b[39;49mattrs)\n\u001b[1;32m     63\u001b[0m process_data \u001b[39m=\u001b[39m newdata\u001b[39m.\u001b[39mpipe(fun, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkargs)\n\u001b[1;32m     65\u001b[0m data \u001b[39m=\u001b[39m process_data\u001b[39m.\u001b[39mdata[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/patch.py:84\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[0;34m(self, data, coords, dims, attrs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata, coords, and dims must be defined to init Patch.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m---> 84\u001b[0m coords \u001b[39m=\u001b[39m get_coord_manager(coords, dims\u001b[39m=\u001b[39;49mdims)\n\u001b[1;32m     85\u001b[0m \u001b[39m# the only case we allow attrs to include coords is if they are both\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m# dicts, in which case attrs might have unit info for coords.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(attrs, Mapping) \u001b[39mand\u001b[39;00m attrs:\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coordmanager.py:924\u001b[0m, in \u001b[0;36mget_coord_manager\u001b[0;34m(coords, dims, attrs)\u001b[0m\n\u001b[1;32m    922\u001b[0m         dims \u001b[39m=\u001b[39m ()\n\u001b[1;32m    923\u001b[0m coords \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m coords \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m coords\n\u001b[0;32m--> 924\u001b[0m coord_map, dim_map \u001b[39m=\u001b[39m _get_coord_dim_map(coords, dims)\n\u001b[1;32m    925\u001b[0m \u001b[39mif\u001b[39;00m attrs:\n\u001b[1;32m    926\u001b[0m     coord_updates, _ \u001b[39m=\u001b[39m separate_coord_info(attrs, dims)\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coordmanager.py:995\u001b[0m, in \u001b[0;36m_get_coord_dim_map\u001b[0;34m(coords, dims)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[39mfor\u001b[39;00m name, coord \u001b[39min\u001b[39;00m coords\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(coord, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 995\u001b[0m         c_map[name], d_map[name] \u001b[39m=\u001b[39m _coord_from_simple(name, coord)\n\u001b[1;32m    996\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m         c_map[name], d_map[name] \u001b[39m=\u001b[39m _maybe_coord_from_nested(coord)\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coordmanager.py:957\u001b[0m, in \u001b[0;36m_get_coord_dim_map.<locals>._coord_from_simple\u001b[0;34m(name, coord)\u001b[0m\n\u001b[1;32m    951\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    952\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCoordinates that are not named the same as dimensions \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust be passed as a tuple of the form: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    954\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(dimension, coord) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    956\u001b[0m     \u001b[39mraise\u001b[39;00m CoordError(msg)\n\u001b[0;32m--> 957\u001b[0m out \u001b[39m=\u001b[39m _get_coord(coord)\n\u001b[1;32m    958\u001b[0m \u001b[39mreturn\u001b[39;00m out, (name,)\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coordmanager.py:945\u001b[0m, in \u001b[0;36m_get_coord_dim_map.<locals>._get_coord\u001b[0;34m(coord)\u001b[0m\n\u001b[1;32m    943\u001b[0m     out \u001b[39m=\u001b[39m get_coord(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcoord)\n\u001b[1;32m    944\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     out \u001b[39m=\u001b[39m get_coord(values\u001b[39m=\u001b[39;49mcoord)\n\u001b[1;32m    946\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coords.py:1075\u001b[0m, in \u001b[0;36mget_coord\u001b[0;34m(values, start, min, stop, max, step, units, dtype)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         val \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1074\u001b[0m         \u001b[39mreturn\u001b[39;00m CoordRange(start\u001b[39m=\u001b[39mval, stop\u001b[39m=\u001b[39mval \u001b[39m+\u001b[39m step, step\u001b[39m=\u001b[39mstep, units\u001b[39m=\u001b[39munits)\n\u001b[0;32m-> 1075\u001b[0m     \u001b[39mreturn\u001b[39;00m CoordMonotonicArray(values\u001b[39m=\u001b[39;49mvalues, units\u001b[39m=\u001b[39;49munits)\n\u001b[1;32m   1076\u001b[0m start, stop, step, monotonic \u001b[39m=\u001b[39m _maybe_get_start_stop_step(values)\n\u001b[1;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/coding/dascore/dascore/core/coords.py:203\u001b[0m, in \u001b[0;36mBaseCoord.check_time_units\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    201\u001b[0m     is_timey \u001b[39m=\u001b[39m is_timedelta64(start) \u001b[39mor\u001b[39;00m is_datetime64(start)\n\u001b[1;32m    202\u001b[0m \u001b[39melif\u001b[39;00m (values \u001b[39m:=\u001b[39m data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     is_timey \u001b[39m=\u001b[39m dtype_time_like(values)\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m is_timey \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39munits\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m (quant \u001b[39m:=\u001b[39m get_quantity(\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    205\u001b[0m     data[\u001b[39m\"\u001b[39m\u001b[39munits\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m quant\n",
      "File \u001b[0;32m~/coding/dascore/dascore/utils/time.py:361\u001b[0m, in \u001b[0;36mdtype_time_like\u001b[0;34m(dtype_or_array)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     dtype_or_array \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(dtype_or_array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, dtype_or_array)\n\u001b[0;32m--> 361\u001b[0m is_datetime \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49missubdtype(dtype_or_array, np\u001b[39m.\u001b[39;49mdatetime64)\n\u001b[1;32m    362\u001b[0m is_timedelta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39missubdtype(dtype_or_array, np\u001b[39m.\u001b[39mtimedelta64)\n\u001b[1;32m    363\u001b[0m \u001b[39mif\u001b[39;00m is_timedelta \u001b[39mor\u001b[39;00m is_datetime:\n",
      "File \u001b[0;32m~/anaconda3/envs/dascore/lib/python3.11/site-packages/numpy/core/numerictypes.py:416\u001b[0m, in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mReturns True if first argument is a typecode lower/equal in type hierarchy.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issubclass_(arg1, generic):\n\u001b[0;32m--> 416\u001b[0m     arg1 \u001b[39m=\u001b[39m dtype(arg1)\u001b[39m.\u001b[39mtype\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issubclass_(arg2, generic):\n\u001b[1;32m    418\u001b[0m     arg2 \u001b[39m=\u001b[39m dtype(arg2)\u001b[39m.\u001b[39mtype\n",
      "\u001b[0;31mTypeError\u001b[0m: Field elements must be 2- or 3-tuples, got '0'"
     ]
    }
   ],
   "source": [
    "# define memory size that you'd like to dedicate to low-frequency processing \n",
    "memory_size = 10000 # in MB\n",
    "patch_length = get_patch_time(memory_size=memory_size, sampling_rate=sampling_rate, num_ch=ch_end-ch_start)\n",
    "print('patch_length = ', patch_length, str(' sec.'))\n",
    "\n",
    "# define the target sampling interval in seconds\n",
    "d_t = 10.0 # so, cutoff_freq = Nyq_new = 1/(2*d_t) = 0.05 hz\n",
    "\n",
    "# define the desired tolerance for getting the edge time (smaller tolerance results a longer eliminated edges in each patch and higher accuracy. 1e-3 is recommended.)\n",
    "tolerance = 1e-3\n",
    "edge_buffer = get_edge_effect_time(sampling_interval=1/sampling_rate, total_T=patch_length, tol=tolerance, freq=1/d_t)\n",
    "print('edge_buffer = ', edge_buffer, str(' sec.'))\n",
    "\n",
    "# pass the spool to the LFProc class\n",
    "lfp = LFProc(sub_sp)\n",
    "lfp.update_processing_parameter(output_sample_interval=d_t, process_patch_size=int(patch_length/d_t), edge_buff_size=int(np.ceil(edge_buffer/d_t)))\n",
    "\n",
    "# set the output folder - Caution: If you set delete_existing=True, you will remove the output_data_folder directory. If you set delete_existing=False, you need to make sure the previous result for the same time range does not exist in the the output_data_folder directory.\n",
    "lfp.set_output_folder(output_data_folder, delete_existing=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do low-frequency processing and process the desired portion of the spool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time()\n",
    "# do lowpass processing on (t_1,t_2) time range\n",
    "t_1 = np.datetime64('2023-08-01T10:00:00')\n",
    "t_2 = np.datetime64('2023-08-02T00:00:00')\n",
    "lfp.process_time_range(t_1,t_2)\n",
    "toc = time()\n",
    "print(f'processing time (sec): {toc-tic}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the results before visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_result = dc.spool(output_data_folder).chunk(time=None) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the low-pass filtered results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Seismogram using Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the channel of interest\n",
    "channel = 1300\n",
    "ch_inx = channel - ch_start\n",
    "filtered_data = sp_result[0].data[:, ch_inx]\n",
    "n_samples = filtered_data.shape[0]\n",
    "num_sec = int(n_samples*d_t)\n",
    "t_filt = np.linspace(0, num_sec, n_samples, endpoint=False)\n",
    "\n",
    "# define the channel range whose mean value you want to subtract from the DAS trace\n",
    "ch_start_demean = 400\n",
    "ch_end_demean = 600\n",
    "demeaned = (filtered_data - np.mean(sp_result[0].data[:,ch_start_demean-ch_start:ch_end_demean-ch_end], axis=1)) \n",
    "\n",
    "# plot the result\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(t_filt, demeaned, label='Low-freq. signal - channel: ' + str(channel))\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Strain rate (1/sec)')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.title('Filtered signal')\n",
    "plt.grid(True)\n",
    "\n",
    "# save the figure into the output_figure_folder directory\n",
    "file_name_lowfreq = '/dascore_lowpass_' + str(int(d_t*2)) + 'sec_filter_channel' + str(channel) + '.jpeg'\n",
    "plt.savefig(output_figure_folder + file_name_lowfreq, dpi=600, format='jpeg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a median filter to remove noise and microseismic events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define window length (number of samples) for the median filter\n",
    "window_size = 9\n",
    "median_filtered_signal = scipy.ndimage.median_filter(demeaned, size=window_size)       \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(t_filt, median_filtered_signal, label='Low-freq. signal - channel: ' + str(channel))\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Strain rate (1/sec)')\n",
    "plt.xlabel('Time (sec)')\n",
    "# plt.ylim(-6e-6, 6e-6)\n",
    "plt.title('Filtered signal')\n",
    "plt.grid(True)\n",
    "\n",
    "# save the figure into the output_figure_folder directory\n",
    "file_name_lowfreq = '/dascore_lowpass_' + str(int(d_t*2)) + 'sec_filtered_median_filtered_channel' + str(channel) + '.jpeg'\n",
    "plt.savefig(output_figure_folder + file_name_lowfreq, dpi=600, format='jpeg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Waterfall plot using Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the filtered results from the result spool\n",
    "filtered_data = sp_result[0].data\n",
    "\n",
    "# define the channel range whose mean you want to subtract from the DAS trace\n",
    "ch_start_demean = 400\n",
    "ch_end_demean = 600\n",
    "mean_array = np.mean(filtered_data[:,ch_start_demean-ch_start:ch_end_demean-ch_start], axis=1)  # Calculate the mean along axis 1\n",
    "mean_array = mean_array.reshape(-1, 1)  # Reshape mean_array to match the shape of full_array\n",
    "\n",
    "# demean the results\n",
    "demeaned_data = (filtered_data - mean_array)\n",
    "\n",
    "# define the channles and seconds you want to plot\n",
    "min_sec = 0\n",
    "max_sec = 13990\n",
    "min_ch = 400\n",
    "max_ch = 1355\n",
    "fig_title = \"low-freq. DAS\"\n",
    "waterfall_plot(demeaned_data.T, min_sec, max_sec, min_ch-ch_start, max_ch-ch_start, ch_start, channel_spacing, 1185, 1/d_t, fig_title, output_figure_folder, \"low_freq_raster_plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply a median filter to remove noise and microseismic events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define window length (number of samples) for the median filter\n",
    "window_size = 5 # means 5*d_t seconds\n",
    "median_filtered_signal = scipy.ndimage.median_filter(demeaned_data, size=window_size)  \n",
    "\n",
    "# define the channles and seconds you want to plot\n",
    "min_sec = 0\n",
    "max_sec = 13990\n",
    "min_ch = 400\n",
    "max_ch = 1355\n",
    "fig_title = \"low-freq. DAS - Median filtered\"\n",
    "waterfall_plot(median_filtered_signal.T, min_sec, max_sec, min_ch-ch_start, max_ch-ch_start,1185, 1/d_t, fig_title, output_figure_folder, \"low_freq_raster_plot_median_filtered\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Waterfall plot using DASCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a sub spool for visualization\n",
    "min_ch = 400\n",
    "max_ch = 1355\n",
    "d_1 = sp_result[0].coords['distance'][min_ch-ch_start] # in meter\n",
    "d_2 = sp_result[0].coords['distance'][max_ch-ch_start] # in meter\n",
    "sub_sp_result = sp_result.select(distance=(d_1, d_2))\n",
    "\n",
    "# get the filtered data from the saved result\n",
    "sub_sp_result_merged = sub_sp_result.chunk(time=None)\n",
    "filtered_data = sub_sp_result_merged[0].data\n",
    "\n",
    "# define the channel range whose mean you want to subtract from the DAS trace\n",
    "ch_start_demean = 400\n",
    "ch_end_demean = 600\n",
    "mean_array = np.mean(filtered_data[:,ch_start_demean-ch_start:ch_end_demean-ch_start], axis=1)  # Calculate the mean along axis 1\n",
    "mean_array = mean_array.reshape(-1, 1)  # Reshape mean_array to match the shape of full_array\n",
    "\n",
    "# demean the results\n",
    "demeaned_data = (filtered_data - mean_array)\n",
    "\n",
    "# make a new patch containing the demeaned_data \n",
    "filtered_demeaned = sub_sp_result_merged[0].new(data=demeaned_data)\n",
    "\n",
    "# plot\n",
    "filtered_demeaned.viz.waterfall(scale=0.01) # scale acts as a clipper for data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dascore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
